# üìä ZK-Steganography Scientific Benchmarks

Comprehensive performance benchmarking suite for the ZK-Steganography system.

---

## üìÅ Directory Structure

```
scientific_benchmarks/
‚îú‚îÄ‚îÄ üìä Main Benchmarks
‚îÇ   ‚îú‚îÄ‚îÄ final_detailed_benchmark.py       ‚≠ê Main 20-point benchmark (RECOMMENDED)
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_benchmark.py        Complete scientific analysis
‚îÇ   ‚îú‚îÄ‚îÄ multi_variable_benchmark.py       Multi-variable testing
‚îÇ   ‚îî‚îÄ‚îÄ comparative_analysis.py           Baseline comparison
‚îÇ
‚îú‚îÄ‚îÄ üîß Utilities
‚îÇ   ‚îú‚îÄ‚îÄ debug_benchmark.py                Anomaly detection tool
‚îÇ   ‚îú‚îÄ‚îÄ explain_cache_warming.py          Cache warming visualization
‚îÇ   ‚îú‚îÄ‚îÄ export_images.py                  Export charts as images
‚îÇ   ‚îú‚îÄ‚îÄ export_tables_as_images.py        Export tables as images
‚îÇ   ‚îî‚îÄ‚îÄ quick_example.py                  Quick demo for beginners
‚îÇ
‚îú‚îÄ‚îÄ üìñ Documentation
‚îÇ   ‚îú‚îÄ‚îÄ BENCHMARK_SUMMARY.md              ‚≠ê Latest results summary
‚îÇ   ‚îú‚îÄ‚îÄ CACHE_WARMING_EXPLANATION.md      ‚≠ê Cache warming guide
‚îÇ   ‚îî‚îÄ‚îÄ DETAILED_BENCHMARK_DOCUMENTATION.md  Complete technical docs
‚îÇ
‚îî‚îÄ‚îÄ üìÅ Results
    ‚îî‚îÄ‚îÄ detailed_benchmark_results/       All generated outputs
        ‚îú‚îÄ‚îÄ benchmark_*.png               High-res charts (300 DPI)
        ‚îú‚îÄ‚îÄ benchmark_*.pdf               Vector charts
        ‚îú‚îÄ‚îÄ results_*.json                Raw data
        ‚îú‚îÄ‚îÄ cache_warming_*.png           Explanation charts
        ‚îî‚îÄ‚îÄ debug_results.json            Debug data
```

---

## üöÄ Quick Start

### Run Main Benchmark (Recommended)
```bash
# Run the complete 20-point benchmark with cache warming
python3 final_detailed_benchmark.py

# Output:
#   ‚Ä¢ 40 tests (2 benchmarks √ó 20 points each)
#   ‚Ä¢ PNG charts (1.2-1.4 MB @ 300 DPI)
#   ‚Ä¢ PDF charts (65-71 KB, vector)
#   ‚Ä¢ JSON data files (11-12 KB)
#   ‚Ä¢ Execution time: ~30-60 seconds
```

### Understand Cache Warming
```bash
# Generate cache warming explanation charts
python3 explain_cache_warming.py

# Output:
#   ‚Ä¢ 6-panel explanation chart
#   ‚Ä¢ 2-panel comparison chart
#   ‚Ä¢ Shows why first test is slower
```

### Debug Anomalies
```bash
# Check for performance anomalies
python3 debug_benchmark.py

# Output:
#   ‚Ä¢ 8 test sizes (128-1024)
#   ‚Ä¢ Detailed logging
#   ‚Ä¢ Anomaly detection
```

---

## üìä Available Benchmarks

### 1. **Final Detailed Benchmark** ‚≠ê (Recommended)
**File:** `final_detailed_benchmark.py`

**Features:**
- ‚úÖ 20 data points per benchmark (arithmetic progression)
- ‚úÖ Cache warming (eliminates cold start)
- ‚úÖ 20-panel visualization (4√ó5 grid)
- ‚úÖ Line charts with clean markers
- ‚úÖ Comprehensive metrics

**Benchmarks:**
1. **Image Size Scaling:** 128√ó128 ‚Üí 1024√ó1024 (fixed message 100 chars)
2. **Message Length Scaling:** 50 ‚Üí 1000 chars (fixed image 512√ó512)

**Metrics (20 panels):**
- Row 1: Embedding/Extraction/Total Time, Throughput, Efficiency
- Row 2: RAM Usage, Image Sizes, Overhead, RAM Efficiency
- Row 3: PSNR, SSIM, MSE, Quality Score, Retention
- Row 4: Bits/pixel, Capacity, Time Breakdown, Success Rate, Summary

**Output:**
- PNG: 1.2-1.4 MB @ 300 DPI
- PDF: 65-71 KB (vector)
- JSON: 11-12 KB (raw data)

**Usage:**
```bash
python3 final_detailed_benchmark.py
```

---

### 2. **Debug Benchmark**
**File:** `debug_benchmark.py`

**Features:**
- 8 test sizes (128, 256, 384, 512, 640, 768, 896, 1024)
- Detailed per-test logging
- Anomaly detection (ratio analysis)
- Helps identify performance issues

**Usage:**
```bash
python3 debug_benchmark.py

# Check results:
cat detailed_benchmark_results/debug_results.json
```

---

### 3. **Comprehensive Benchmark**
**File:** `comprehensive_benchmark.py`

**Features:**
- Multiple benchmark types
- Statistical analysis
- Extensive metrics
- Publication-ready

**Usage:**
```bash
python3 comprehensive_benchmark.py
```

---

### 4. **Multi-Variable Benchmark**
**File:** `multi_variable_benchmark.py`

**Features:**
- Tests multiple variables independently:
  - Image sizes (256, 512, 1024, 2048)
  - Message lengths (10, 50, 200, 800, 2000)
  - Message types (text, binary, random)
  - Proof sizes
- Separate analysis per variable
- Comprehensive output

**Usage:**
```bash
python3 multi_variable_benchmark.py
```

---

### 5. **Comparative Analysis**
**File:** `comparative_analysis.py`

**Features:**
- Compare with baseline methods
- Side-by-side comparison
- Statistical significance tests

**Usage:**
```bash
python3 comparative_analysis.py
```

---

## üìñ Documentation

### 1. **Benchmark Summary** ‚≠ê
**File:** `BENCHMARK_SUMMARY.md`

Latest benchmark results with:
- Complete test results
- Performance characteristics
- Visual improvements
- Key findings
- Usage instructions

### 2. **Cache Warming Explanation** ‚≠ê
**File:** `CACHE_WARMING_EXPLANATION.md`

Comprehensive guide covering:
- What is cold start?
- What is cache warming?
- Why it matters for benchmarks
- Implementation examples
- Technical deep dive
- Common pitfalls

### 3. **Detailed Documentation**
**File:** `DETAILED_BENCHMARK_DOCUMENTATION.md`

Complete technical documentation:
- All metrics explained
- Interpretation guide
- Performance characteristics
- Best practices

---

## üìä Latest Results (Oct 15, 2025)

### Image Size Scaling (20 points)
```
Configuration:
  ‚Ä¢ Message: 100 chars (fixed)
  ‚Ä¢ Image: 128√ó128 ‚Üí 1024√ó1024
  ‚Ä¢ Cache warming: YES

Results:
  ‚Ä¢ Tests: 20/20 (100%)
  ‚Ä¢ Time: 3.6 - 9.2 ms
  ‚Ä¢ RAM: 0.0 - 13.8 MB
  ‚Ä¢ R¬≤: 0.9876 (excellent fit)
  ‚Ä¢ Scaling: Linear O(n)
```

### Message Length Scaling (20 points)
```
Configuration:
  ‚Ä¢ Image: 512√ó512 (fixed)
  ‚Ä¢ Message: 50 ‚Üí 1000 chars
  ‚Ä¢ Cache warming: YES

Results:
  ‚Ä¢ Tests: 20/20 (100%)
  ‚Ä¢ Time: 2.6 - 42.3 ms
  ‚Ä¢ RAM: ~0 MB overhead
  ‚Ä¢ R¬≤: 0.9924 (near-perfect)
  ‚Ä¢ Scaling: Linear O(m)
```

### Key Findings
- ‚úÖ No anomalies at any size
- ‚úÖ Linear scaling confirmed
- ‚úÖ Predictable performance
- ‚úÖ Excellent R¬≤ > 0.98

---

## üé® Visualization Features

### Chart Improvements (v2.0)
```python
# Optimized markers:
markersize=5      # Smaller, cleaner (was 8)
linewidth=2.5     # Better balance (was 3.0)
markeredgewidth=1 # Subtle outline (was 1.5)
```

**Benefits:**
- ‚úÖ Cleaner professional look
- ‚úÖ Less visual clutter
- ‚úÖ Better readability
- ‚úÖ Easier to see trends

---

## üîß Requirements

### Python Dependencies
```bash
# Core requirements:
pip install numpy pillow matplotlib psutil

# Optional (for quality metrics):
pip install scikit-image

# Optional (for statistical analysis):
pip install scipy
```

### System Requirements
- Python 3.8+
- ~100 MB disk space (for outputs)
- ~50 MB RAM (during execution)

---

## üìù Usage Examples

### Example 1: Quick Benchmark
```bash
# Run main benchmark and view results
python3 final_detailed_benchmark.py
ls -lh detailed_benchmark_results/
```

### Example 2: Custom Analysis
```python
from final_detailed_benchmark import FinalDetailedBenchmark

# Create benchmark instance
bench = FinalDetailedBenchmark()

# Run specific benchmark
bench.run_image_size_benchmark()

# Access results
print(f"Total tests: {len(bench.results)}")
print(f"Avg time: {sum(r['total_time_ms'] for r in bench.results) / len(bench.results):.2f}ms")
```

### Example 3: Debug Performance
```bash
# Check for anomalies
python3 debug_benchmark.py

# View detailed logs
cat detailed_benchmark_results/debug_results.json | jq .
```

---

## üêõ Troubleshooting

### Issue: scikit-image not found
```
‚ö†Ô∏è scikit-image not available - quality metrics will be zeros

Solution:
pip install scikit-image
```

### Issue: First test is slower
```
This is expected (cold start). Solution:
‚úÖ Use final_detailed_benchmark.py (has cache warming)
‚úÖ Or add warmup run manually
```

### Issue: Out of memory
```
For very large images (>2048√ó2048):
‚Ä¢ Reduce test points (20 ‚Üí 10)
‚Ä¢ Use smaller max size (1024 ‚Üí 768)
‚Ä¢ Close other applications
```

---

## üìä Output Files

### PNG Charts (High Resolution)
```
Size: 1.2-1.4 MB each
DPI: 300 (publication quality)
Format: RGB
Dimensions: 7200√ó4800 pixels (24√ó16 inches)
```

### PDF Charts (Vector)
```
Size: 65-71 KB each
Format: Vector graphics
Scalable: Infinite resolution
Perfect for: Papers, presentations
```

### JSON Data (Raw)
```
Size: 11-12 KB each
Format: Pretty-printed JSON
Contains: All raw measurements
Perfect for: Further analysis
```

---

## üéØ Best Practices

### 1. Always Use Cache Warming
```python
# ‚úÖ GOOD
warmup()
results = benchmark()

# ‚ùå BAD
results = benchmark()  # First test will be slower
```

### 2. Use Consistent Test Sizes
```python
# ‚úÖ GOOD: Arithmetic progression
sizes = np.linspace(128, 1024, 20)

# ‚ùå BAD: Random sizes
sizes = [128, 200, 450, 1024]  # Hard to analyze
```

### 3. Save Raw Data
```python
# Always save JSON for later analysis
with open('results.json', 'w') as f:
    json.dump(results, f, indent=2)
```

### 4. Document Test Conditions
```python
# Include system info in results
results['system'] = {
    'cpu': psutil.cpu_count(),
    'ram': psutil.virtual_memory().total,
    'python': sys.version
}
```

---

## üî¨ Advanced Usage

### Custom Benchmark Configuration
```python
# Modify test parameters
IMAGE_SIZES = np.linspace(256, 2048, 30)  # 30 points instead of 20
MESSAGE_LENGTHS = np.logspace(1, 3, 25)    # Logarithmic scale
WARMUP_RUNS = 3                            # Multiple warmups
```

### Parallel Execution
```python
# NOT RECOMMENDED: Can skew results
# Benchmarks should run sequentially for accuracy
```

### Export to Different Formats
```python
# Export to CSV
import pandas as pd
df = pd.DataFrame(results)
df.to_csv('results.csv', index=False)

# Export to LaTeX
df.to_latex('results.tex')
```

---

## üìö Additional Resources

### Documentation
- `BENCHMARK_SUMMARY.md` - Latest results
- `CACHE_WARMING_EXPLANATION.md` - Technical guide
- `DETAILED_BENCHMARK_DOCUMENTATION.md` - Complete docs

### Visualization Tools
- `explain_cache_warming.py` - Generate explanation charts
- `export_images.py` - Export in different formats
- `export_tables_as_images.py` - Convert tables to images

### Analysis Tools
- `debug_benchmark.py` - Detect anomalies
- `comparative_analysis.py` - Compare methods
- `multi_variable_benchmark.py` - Multi-factor analysis

---

## ü§ù Contributing

To add new benchmarks:

1. Create new `.py` file in `scientific_benchmarks/`
2. Follow naming convention: `*_benchmark.py`
3. Include docstring with description
4. Save results to `detailed_benchmark_results/`
5. Update this README

---

## üìû Support

For issues or questions:
- Check `CACHE_WARMING_EXPLANATION.md` for common issues
- Review `BENCHMARK_SUMMARY.md` for latest results
- Run `debug_benchmark.py` to diagnose problems

---

## ‚úÖ Status

**Benchmark Suite:** ‚úÖ Production Ready  
**Last Updated:** October 15, 2025  
**Version:** 2.0 (with improved visualization)  
**Tests Passed:** 40/40 (100%)  
**Documentation:** Complete  

---

**Made with ‚ù§Ô∏è for ZK-Steganography**
